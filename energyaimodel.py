# -*- coding: utf-8 -*-
"""EnergyAIModel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xh05gTmHbOg64RFG_lnFvXTBleiigjA9
"""

from google.colab import files

# This will prompt you to upload a file
uploaded = files.upload()

import pandas as pd
import numpy as np
df = pd.read_csv('coteq_electricity_2013.csv')

# Display the first few rows of the DataFrame to confirm it loaded correctly
df.head()

feature_columns = ['smartmeter_perc', 'delivery_perc']  # Columns for X
target_column = 'annual_consume'  # Column for Y

# Create X and Y
X = df[feature_columns].values.tolist()  # Converts the DataFrame subset to a list of lists
Y = df[target_column].tolist()  # Converts the Series to a list

def z_score_normalize(Y):
    Y = np.array(Y)
    mean = Y.mean()
    std = Y.std()
    normalized_Y = (Y - mean) / std
    return normalized_Y #explain this in the paper (Z normalization)

Y = z_score_normalize(Y)

# Display the first few rows of X and Y to verify
print("X:")

print("\nY:")

from sklearn.model_selection import train_test_split

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)
print(X_train[0])
print(Y_train[0])

print(X_train)
print(len(X_test))

print(len(Y_train))
print(len(Y_test))

from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler, LabelEncoder

import numpy as np

from sklearn import datasets, linear_model
from sklearn.metrics import mean_squared_error, r2_score

#linear regression
linearregression = linear_model.LinearRegression()

# Train the model using the training sets
linearregression.fit(X_train, Y_train)

# Make predictions using the testing set
Y_pred_lr_train = linearregression.predict(X_train)
Y_pred_lr_test = linearregression.predict(X_test)

# The coefficients
print("Coefficients: \n", linearregression.coef_)
# The mean squared error
print("Mean squared error train: %.4f" % mean_squared_error(Y_train, Y_pred_lr_train))
print("Mean squared error test: %.4f" % mean_squared_error(Y_test, Y_pred_lr_test))

from sklearn.neural_network import MLPRegressor
#neural network

mlpr = MLPRegressor(random_state=1, max_iter=20).fit(X_train, Y_train)
Y_pred_mlp_test = mlpr.predict(X_test)
Y_pred_mlp_train = mlpr.predict(X_train)


print("Mean squared error test: %.4f" % mean_squared_error(Y_test, Y_pred_mlp_test))
print("Mean squared error train: %.4f" % mean_squared_error(Y_train, Y_pred_mlp_train))

from sklearn.tree import DecisionTreeRegressor
#decision tree

regr_1 = DecisionTreeRegressor(max_depth=1)
regr_2 = DecisionTreeRegressor(max_depth=25)
regr_1.fit(X_train, Y_train)
regr_2.fit(X_train, Y_train)

# Predict
Y_pred1_dt = regr_1.predict(X_test)
Y_pred2_dt = regr_2.predict(X_test)

Y_predTrain1 = regr_1.predict(X_train)
Y_predTrain2 = regr_2.predict(X_train)

print("Mean squared error test (1): %.4f" % mean_squared_error(Y_test, Y_pred1_dt))
print("Mean squared error test (2): %.4f" % mean_squared_error(Y_test, Y_pred2_dt))
print("Mean squared error train (1): %.4f" % mean_squared_error(Y_train, Y_predTrain1))
print("Mean squared error train (2): %.4f" % mean_squared_error(Y_train, Y_predTrain2))

from sklearn.ensemble import RandomForestRegressor

rfc = RandomForestRegressor(max_depth=1, random_state=0, n_estimators=50)
rfc.fit(X_train, Y_train)


Y_pred1_rf = rfc.predict(X_test)
Y_pred2_rf = rfc.predict(X_train)


print("Mean squared error test: %.4f" % mean_squared_error(Y_test, Y_pred1_rf))
print("Mean squared error train: %.4f" % mean_squared_error(Y_train, Y_pred2_rf))

def percentError(list_1, list_2): #unused
  sum = 0
  for i in range(len(list_1)):
    percentage = abs(list_1[i])-abs(list_2[i]) / abs(list_1[i])
    sum += percentage

  print(sum/len(list_1))

percentError(Y_pred_lr_test, Y_test)

average_of_all = (Y_pred_lr_test + Y_pred_mlp_test + Y_pred1_rf + Y_pred1_dt) / 4
print("Mean squared error: %.4f" % mean_squared_error(Y_test, average_of_all))
percentError(average_of_all, Y_test)

best2average = (Y_pred1_rf + Y_pred_mlp_test) / 2
print("Mean squared error: %.4f" % mean_squared_error(Y_test, best2average))
percentError(best2average, Y_test)

#method of combining each model
lr_error = mean_squared_error(Y_test, Y_pred_lr_test)
mlp_error = mean_squared_error(Y_test, Y_pred_mlp_test)
dt_error = mean_squared_error(Y_test, Y_pred1_dt)
rf_error = mean_squared_error(Y_test, Y_pred1_rf)

total_results = (1/lr_error)+(1/mlp_error)+(1/dt_error)+(1/rf_error)
weight = (1/total_results)
print(weight)

weighted_lr_error = (weight/lr_error) # the weights we multiply by
weighted_mlp_error = (weight/mlp_error)
weighted_dt_error = (weight/dt_error)
weighted_rf_error = (weight/rf_error)
print(weighted_lr_error + weighted_mlp_error + weighted_dt_error + weighted_rf_error)

weighted_average = ((Y_pred_lr_test * weighted_lr_error) + (Y_pred_mlp_test * weighted_mlp_error) + (Y_pred1_rf * weighted_rf_error) + (Y_pred1_dt * weighted_dt_error))
print("Mean squared error: %.4f" % mean_squared_error(Y_test, weighted_average))